# Stress 테스트 실습 가이드

시스템의 한계점(Breaking Point)을 찾고, 장애 발생 시점과 양상을 파악합니다.

---

## 프로파일 개요

### 목적

**시스템의 한계점(breaking point)**을 찾습니다.
VUs를 계속 증가시켜 시스템이 언제, 어떻게 실패하는지 확인합니다.

### 사용 시점

- 시스템의 최대 처리량(TPS) 확인
- 대규모 이벤트(블랙 프라이데이 등) 대비
- 장애 발생 시점과 양상 파악
- 스케일 아웃 필요 시점 결정

### 테스트 구성

```text
┌─────────────────────────────────────────────────────────────────────────────────┐
│  VUs                                                                            │
│  3000 ───────────────────────────────────────────────────────────┐              │
│                                                                   │              │
│  2500 ──────────────────────────────────────────────┐            │              │
│                                                      │            │              │
│  2000 ─────────────────────────────────┐            │            │              │
│                                         │            │            │              │
│  1500 ────────────────────┐            │            │            │              │
│                            │            │            │            │              │
│  1000 ───────────┐        │            │            │            │              │
│                   │        │            │            │            │              │
│   500 ────┐       │        │            │            │            │              │
│            │       │        │            │            │            │              │
│   200 ─────┤       │        │            │            │            │              │
│            │       │        │            │            │            │              │
│     0 ─────┴───────┴────────┴────────────┴────────────┴────────────┴─────────   │
│        0    2분    5분      8분        11분        14분        17분   20분 22분  │
└─────────────────────────────────────────────────────────────────────────────────┘
```

### 단계별 의도

| 단계 | 시간 | VUs | 의도 |
|------|------|-----|------|
| **1. 초기 부하** | 0~2분 | 0→200 | 기본 부하 레벨 도달. 워밍업 |
| **2. 첫 번째 증가** | 2~5분 | 200→500 | 일반적인 피크 부하 시뮬레이션 |
| **3. 두 번째 증가** | 5~8분 | 500→1000 | 예상 최대 부하의 2배 수준 |
| **4. 세 번째 증가** | 8~11분 | 1000→1500 | **주의**: 여기서부터 에러 발생 가능성 높음 |
| **5. 네 번째 증가** | 11~14분 | 1500→2000 | 시스템 한계에 근접 |
| **6. 다섯 번째 증가** | 14~17분 | 2000→2500 | **한계점 탐색**: 응답 시간 급격히 증가 예상 |
| **7. 최대 부하** | 17~20분 | 2500→3000 | **브레이킹 포인트 확인**: 시스템 한계 도달 |
| **8. 쿨다운** | 20~22분 | 3000→0 | 부하 제거 후 복구 가능 여부 확인 |

### 성공 기준 (Thresholds)

```javascript
thresholds: {
  http_req_duration: ['p(95)<2000'],  // 스트레스 테스트는 관대하게 2초
  http_req_failed: ['rate<0.20'],     // 20% 에러율까지 허용
}
```

> **중요**: 스트레스 테스트의 목적은 "통과"가 아니라 **"언제 실패하는지 찾기"**입니다.
> 에러 없이 완주했다면 VUs를 더 높여야 합니다.

### 해석 가이드

| 관찰 패턴 | 의미 | 조치 |
|-----------|------|------|
| **응답 시간 선형 증가** | 시스템이 정상적으로 처리 중 | 추가 여유 있음 |
| **응답 시간 급격히 증가** | 특정 리소스 포화 | 병목 지점 확인 필요 |
| **에러율 급증** | 시스템 한계 도달 | 이 VUs 직전이 최대 처리량 |
| **응답 시간 무한 증가 후 타임아웃** | 시스템 붕괴 | 큐잉/서킷브레이커 필요 |

---

## 사전 준비

### 환경 설정

```powershell
# 1. 권장 설정으로 시작 (Ramp-Up에서 찾은 적정값 사용)
$env:DB_POOL_SIZE=30; $env:UV_THREADPOOL_SIZE=16; docker-compose up -d

# 2. 헬스 체크
curl http://localhost:3000/health

# 3. 워밍업 (선택사항)
curl http://localhost:3000/api/scenarios/simple-query?id=1
```

### 실행 명령어

```powershell
# 로컬 k6 사용 (권장 - 약 22분 소요)
k6 run k6/profiles/stress.js

# 시나리오 지정
k6 run k6/profiles/stress.js --env SCENARIO=simple-query

# 결과 파일 위치
cat ./stress-summary.json
```

> **주의**: 스트레스 테스트는 시스템에 큰 부하를 주므로 운영 환경에서 실행하지 마세요.

---

## 실습 1: 시스템 한계점(Breaking Point) 찾기

### 실습 1 목적

VUs를 증가시키며 **시스템이 처리할 수 있는 최대 부하**를 찾습니다.
에러율이 급증하는 시점이 시스템의 한계점입니다.

### 실습 1 배경 지식

**Breaking Point**란?

- 시스템이 정상적으로 처리할 수 있는 최대 부하 지점
- 이 지점을 넘으면 에러율이 급격히 증가
- 응답 시간이 선형이 아닌 지수적으로 증가하기 시작

```text
[정상 구간]     [경계 구간]     [장애 구간]
   │              │              │
   ▼              ▼              ▼
───────────▶──────▶─────────────▶
  선형 증가    급격 증가    에러 급증
```

### 실습 1 단계

**Step 1: Stress 테스트 실행**

```powershell
# 충분한 풀 사이즈로 시작
$env:DB_POOL_SIZE=50; docker-compose up -d

# 스트레스 테스트 실행
k6 run k6/profiles/stress.js
```

**Step 2: 실시간 모니터링**

별도 터미널에서 실행:

```powershell
# 메트릭 모니터링
while ($true) {
    $timestamp = Get-Date -Format "HH:mm:ss"
    $metrics = (curl -s http://localhost:3000/api/metrics/pools) | ConvertFrom-Json
    Write-Host "$timestamp - Active: $($metrics.database.activeConnections), Waiting: $($metrics.database.waitingRequests)"
    Start-Sleep 5
}

# Docker 리소스 모니터링
docker stats
```

**Step 3: 결과 분석**

테스트 완료 후 결과 파일에서 Breaking Point 찾기:

```powershell
# 결과 확인
cat ./stress-summary.json
```

**Step 4: 기록**

| VUs 구간 | TPS | P95 응답 시간 | 에러율 | 상태 |
|----------|-----|---------------|--------|------|
| 0~500 | | | | |
| 500~1000 | | | | |
| 1000~1500 | | | | |
| 1500~2000 | | | | |
| 2000~2500 | | | | |
| 2500~3000 | | | | |

### 실습 1 핵심 관찰 포인트

- **에러율이 급증한 VUs**: 이 직전이 실제 한계점
- **응답 시간이 급격히 증가한 VUs**: 리소스 포화 시작점
- **TPS가 더 이상 증가하지 않는 VUs**: 처리량 한계 도달

### 실습 1 학습 포인트

- 한계점 = 에러율 급증 직전의 VUs
- 안전한 운영 범위 = 한계점의 70~80%
- 스케일 아웃 필요 시점 = 한계점의 60~70%에 도달했을 때

---

## 실습 2: 에러 패턴 분석과 장애 양상 파악

### 실습 2 목적

시스템이 한계에 도달했을 때 **어떤 종류의 에러가 발생하는지** 분석합니다.
에러의 종류에 따라 해결 방법이 다릅니다.

### 실습 2 배경 지식

주요 에러 유형:

| 에러 | 원인 | 해결 방법 |
|------|------|-----------|
| `POOL_EXHAUSTED` | DB 커넥션 풀 고갈 | 풀 사이즈 증가 |
| `ETIMEDOUT` | 커넥션 획득 타임아웃 | 타임아웃 증가 또는 풀 증가 |
| `ECONNRESET` | 커넥션 강제 종료 | 부하 감소 또는 스케일 아웃 |
| `HTTP 503` | 서비스 불가 | 서킷브레이커 또는 큐잉 |
| `HTTP 504` | 게이트웨이 타임아웃 | 업스트림 성능 개선 |

### 실습 2 단계

**Step 1: 의도적으로 한계 초과 부하 생성**

```powershell
# 작은 풀 사이즈로 빠르게 한계 도달
$env:DB_POOL_SIZE=10; docker-compose up -d

# 스트레스 테스트 실행
k6 run k6/profiles/stress.js
```

**Step 2: API 로그 확인**

```powershell
# 에러 로그 확인
docker-compose logs api | Select-String -Pattern "error|Error|ERROR"

# 실시간 로그 모니터링
docker-compose logs -f api
```

**Step 3: 에러 패턴 기록**

| 시점 (VUs) | 첫 에러 유형 | 에러 메시지 | 발생 빈도 |
|------------|--------------|-------------|-----------|
| | | | |
| | | | |
| | | | |

**Step 4: 에러 발생 순서 분석**

일반적인 에러 전파 순서:

```text
1. waitingRequests 급증
   ↓
2. acquireTime 타임아웃 (ETIMEDOUT)
   ↓
3. 요청 실패 (POOL_EXHAUSTED)
   ↓
4. 연쇄 실패 (응답 대기 요청들도 실패)
```

### 실습 2 핵심 관찰 포인트

- **첫 번째로 발생하는 에러 유형**: 근본 원인 파악에 중요
- **에러 전파 패턴**: 한 에러가 다른 에러를 유발하는지
- **에러 발생 VUs 기록**: 장애 예방을 위한 기준선

### 실습 2 학습 포인트

- 에러 유형에 따라 해결 방법이 다름
- 첫 번째 에러가 근본 원인일 가능성 높음
- 에러 로그는 장애 분석의 핵심 자료

---

## 실습 3: 복구 능력(Resilience) 테스트

### 실습 3 목적

시스템이 과부하 상태에서 **부하가 감소했을 때 정상적으로 복구되는지** 확인합니다.
복구 시간과 복구 후 성능을 측정합니다.

### 실습 3 배경 지식

**Resilience (회복력)**이란?

- 장애나 과부하 상태에서 정상 상태로 복구되는 능력
- 복구 시간(MTTR: Mean Time To Recovery)이 중요한 지표
- 복구 후 성능이 이전과 동일해야 완전한 복구

```text
부하
  │    과부하 구간
  │   ┌───────┐
  │   │       │    복구 구간
  │───┤       ├───────────────────
  │   │       │
  └───┴───────┴──────────────────▶ 시간
      장애발생  부하감소  복구완료
```

### 실습 3 단계

**Step 1: 정상 상태 기준선 측정**

```powershell
$env:DB_POOL_SIZE=30; docker-compose up -d

# 저부하 테스트로 기준선 측정
k6 run k6/scenarios/simple-query.js --env VUS=50 --env DURATION=60s
```

기준선 기록:

| 지표 | 값 |
|------|-----|
| P95 응답 시간 | |
| 에러율 | |
| TPS | |

**Step 2: 과부하 발생 및 복구 관찰**

```powershell
# 스트레스 테스트 실행 (쿨다운 구간에서 복구 관찰)
k6 run k6/profiles/stress.js
```

쿨다운 구간(20~22분)에서 관찰:

- 응답 시간이 정상으로 돌아오는 시점
- 에러가 멈추는 시점
- `waitingRequests`가 0이 되는 시점

**Step 3: 복구 후 성능 확인**

스트레스 테스트 완료 직후:

```powershell
# 즉시 저부하 테스트 실행
k6 run k6/scenarios/simple-query.js --env VUS=50 --env DURATION=60s
```

**Step 4: 결과 비교**

| 시점 | P95 응답 시간 | 에러율 | TPS |
|------|---------------|--------|-----|
| 기준선 (Step 1) | | | |
| 복구 후 (Step 3) | | | |
| 차이 | | | |

### 실습 3 핵심 관찰 포인트

- **복구 시간**: 부하 감소 후 정상화까지 걸린 시간
- **복구 완전성**: 기준선 대비 성능 차이
- **잔여 영향**: 복구 후에도 남아있는 성능 저하

### 실습 3 학습 포인트

- 빠른 복구는 시스템 안정성의 핵심
- 복구 후 성능 저하가 있다면 리소스 누수 가능성
- 서킷브레이커, Rate Limiting이 복구 속도에 영향

---

## 실습 4: 시나리오별 한계점 비교

### 실습 4 목적

**다양한 워크로드에서 시스템의 한계점이 어떻게 달라지는지** 비교합니다.
워크로드 특성에 따라 병목 지점이 다름을 이해합니다.

### 실습 4 배경 지식

워크로드별 특성:

| 시나리오 | 주요 리소스 | 예상 병목 |
|----------|-------------|-----------|
| simple-query | DB 커넥션 | 커넥션 풀 |
| complex-query | DB 커넥션 + CPU | 커넥션 풀 + 쿼리 시간 |
| cpu-intensive | CPU + libuv | 스레드 풀 |
| file-and-db | libuv + DB | 파일 핸들 + 커넥션 |
| external-api | 네트워크 | 동시 연결 수 |
| mixed | 복합 | 가장 느린 시나리오 |

### 실습 4 단계

**Step 1: simple-query 한계점 측정**

```powershell
$env:DB_POOL_SIZE=30; $env:UV_THREADPOOL_SIZE=4; docker-compose up -d
k6 run k6/profiles/stress.js --env SCENARIO=simple-query
```

**Step 2: cpu-intensive 한계점 측정**

```powershell
$env:DB_POOL_SIZE=30; $env:UV_THREADPOOL_SIZE=16; docker-compose up -d
k6 run k6/profiles/stress.js --env SCENARIO=cpu-intensive
```

**Step 3: complex-query 한계점 측정**

```powershell
$env:DB_POOL_SIZE=50; $env:UV_THREADPOOL_SIZE=4; docker-compose up -d
k6 run k6/profiles/stress.js --env SCENARIO=complex-query
```

**Step 4: 결과 비교**

| 시나리오 | Breaking Point (VUs) | 최대 TPS | 주요 병목 |
|----------|----------------------|----------|-----------|
| simple-query | | | |
| cpu-intensive | | | |
| complex-query | | | |

### 실습 4 핵심 관찰 포인트

- **시나리오별 Breaking Point 차이**: 어떤 워크로드가 가장 빨리 한계 도달?
- **병목 지점의 차이**: 각 시나리오에서 어떤 메트릭이 먼저 이상 징후?
- **최적 설정의 차이**: 시나리오별로 최적 풀 사이즈가 다른지?

### 실습 4 학습 포인트

- 워크로드에 따라 시스템 한계점이 크게 다름
- 가장 느린/무거운 워크로드가 전체 시스템 한계 결정
- 실제 운영에서는 mixed 시나리오 결과가 가장 현실적

---

## 트러블슈팅

### 문제: 테스트 시작부터 에러 발생

**원인**: 풀 사이즈가 너무 작거나 환경 미준비

```powershell
# 풀 사이즈 확인 및 증가
$env:DB_POOL_SIZE=50; docker-compose up -d

# 워밍업
curl http://localhost:3000/health
```

### 문제: CPU 100%로 테스트 불가

**원인**: 시스템 리소스 부족

```powershell
# Docker 리소스 제한 확인
docker stats

# 불필요한 컨테이너 정리
docker system prune
```

### 문제: k6가 중간에 멈춤

**원인**: k6 자체 리소스 부족

```powershell
# k6 프로세스 확인
Get-Process k6

# 더 낮은 VUs로 재시도
k6 run k6/profiles/stress.js --env MAX_VUS=1000
```

---

## 다음 단계

Stress 테스트로 시스템 한계점을 파악했다면, 다음 프로파일로 진행하세요:

1. **[Soak 테스트](guide-soak.md)** - 장시간 안정성 검증
   - 메모리 누수 탐지
   - 커넥션 풀 안정성 확인
   - 시간에 따른 성능 저하 추적

2. **[Ramp-Up 테스트](guide-ramp-up.md)** - 기본 튜닝으로 돌아가기
   - 한계점 기반으로 적정 풀 사이즈 재설정
   - 튜닝 효과 재검증
