# 스레드/커넥션 풀 튜닝 실습 환경 구축 요청

## 목표
1000~2000 TPS 부하를 시뮬레이션하여 커넥션 풀과 스레드 풀(libuv) 튜닝 효과를 
직접 관찰하고 학습할 수 있는 환경을 만들어줘.

## 기술 스택
- Backend: NestJS (Node.js)
- Database: MySQL 8.0
- ORM: TypeORM
- Container: Docker, Docker Compose
- Load Testing: k6
- Thread Pool: libuv (UV_THREADPOOL_SIZE)

## 프로젝트 구조
```
pool-tuning-lab/
├── docker-compose.yml
├── api/                    # NestJS 애플리케이션
│   ├── Dockerfile
│   ├── src/
│   │   ├── scenarios/      # 시나리오별 컨트롤러/서비스
│   │   ├── database/       # TypeORM 설정
│   │   └── metrics/        # 풀 상태 모니터링
│   └── ...
├── k6/                     # 부하 테스트 스크립트
│   ├── scenarios/
│   └── ...
├── mysql/
│   └── init.sql            # 초기 스키마 및 더미 데이터
└── README.md               # 실습 가이드
```

## 요구사항

### 1. API 시나리오 (각각 다른 특성을 가진 엔드포인트)

#### 시나리오 A: 단순 쿼리 (빠른 I/O)
- `GET /api/scenarios/simple-query`
- 단일 테이블에서 PK로 1건 조회
- 예상 응답시간: 5~10ms
- 목적: 커넥션 풀이 충분할 때 vs 부족할 때 비교

#### 시나리오 B: 복잡한 쿼리 (느린 I/O)
- `GET /api/scenarios/complex-query`
- JOIN 3개 이상, 집계 함수 포함
- 인위적으로 100~200ms 걸리도록 설계
- 목적: 쿼리가 느릴 때 커넥션 풀 사이즈 영향 관찰

#### 시나리오 C: CPU 집약 작업
- `POST /api/scenarios/cpu-intensive`
- bcrypt 해싱, JSON 대량 파싱 등
- libuv 스레드 풀을 사용하는 작업 포함
- 목적: UV_THREADPOOL_SIZE 변경 효과 관찰

#### 시나리오 D: 파일 I/O + DB
- `POST /api/scenarios/file-and-db`
- 파일 읽기/쓰기 (fs 모듈 사용) + DB 저장
- 목적: libuv 스레드 풀과 DB 커넥션 풀 동시 튜닝

#### 시나리오 E: 외부 API 호출 시뮬레이션
- `GET /api/scenarios/external-api`
- setTimeout으로 100~300ms 지연 시뮬레이션
- 목적: 논블로킹 I/O와 풀 사이즈 관계 이해

#### 시나리오 F: 혼합 워크로드
- `POST /api/scenarios/mixed`
- 위 시나리오들을 랜덤 비율로 조합
- 목적: 실제 운영 환경과 유사한 상황 시뮬레이션

### 2. 데이터베이스 설계
```sql
-- 충분한 데이터로 현실적인 쿼리 성능 테스트
-- users: 100,000건
-- orders: 500,000건  
-- products: 10,000건
-- order_items: 1,000,000건
```

인덱스 유무에 따른 차이도 테스트할 수 있도록 설계해줘.

### 3. 커넥션 풀 설정 (TypeORM)

환경 변수로 조절 가능하게:
```typescript
// 조절 가능한 파라미터
DB_POOL_SIZE=10              // 커넥션 풀 사이즈
DB_POOL_ACQUIRE_TIMEOUT=10000 // 커넥션 획득 타임아웃
DB_POOL_IDLE_TIMEOUT=30000   // 유휴 커넥션 타임아웃
```

### 4. libuv 스레드 풀 설정

Dockerfile에서 환경변수로 조절:
```dockerfile
ENV UV_THREADPOOL_SIZE=4  # 기본값 4, 최대 1024
```

### 5. 메트릭 수집 엔드포인트

`GET /api/metrics/pools` 응답 예시:
```json
{
  "database": {
    "totalConnections": 10,
    "activeConnections": 7,
    "idleConnections": 3,
    "waitingRequests": 12,
    "acquireTime": {
      "avg": 45,
      "p95": 120,
      "p99": 250
    }
  },
  "libuv": {
    "threadPoolSize": 4,
    "pendingTasks": 15
  },
  "application": {
    "requestsPerSecond": 1250,
    "avgResponseTime": 85,
    "errorRate": 0.02
  }
}
```

### 6. k6 부하 테스트 스크립트

각 시나리오별로 스크립트 작성:
```javascript
// k6/scenarios/connection-pool-test.js
// - 점진적으로 TPS 증가 (100 → 500 → 1000 → 2000)
// - 각 단계에서 메트릭 수집
// - 에러율, 응답시간 p95/p99 리포트
```

테스트 프로파일:
- `ramp-up`: 점진적 부하 증가
- `stress`: 한계점 찾기
- `soak`: 장시간 안정성 테스트

### 7. Docker Compose 설정
```yaml
# 리소스 제한으로 현실적인 환경 시뮬레이션
services:
  api:
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 1G
  
  mysql:
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
```

### 8. 실습 가이드 (README.md)

다음 실습 시나리오를 포함한 가이드 작성:

#### 실습 1: 커넥션 풀 사이즈 영향 관찰
```bash
# 커넥션 5개로 1000 TPS 테스트
DB_POOL_SIZE=5 docker-compose up -d
k6 run k6/scenarios/simple-query.js --vus 100 --duration 60s

# 커넥션 20개로 동일 테스트
DB_POOL_SIZE=20 docker-compose up -d
k6 run k6/scenarios/simple-query.js --vus 100 --duration 60s
```

#### 실습 2: 쿼리 속도와 커넥션 풀 관계
- 빠른 쿼리 (10ms) vs 느린 쿼리 (200ms)에서 필요한 커넥션 수 비교

#### 실습 3: libuv 스레드 풀 튜닝
```bash
# UV_THREADPOOL_SIZE=4 vs 16 vs 64 비교
# CPU 집약 작업에서 차이 관찰
```

#### 실습 4: 병목 지점 찾기
- 메트릭을 보고 현재 병목이 커넥션 풀인지, 스레드 풀인지, 
  CPU인지, 메모리인지 판단하는 방법

#### 실습 5: 최적 설정 찾기
- 주어진 리소스(2 CPU, 1GB RAM)에서 최대 TPS 달성하기

## 추가 요청사항

1. 모든 설정값은 환경변수로 조절 가능하게 해줘
2. 로그에 커넥션 획득 시간, 쿼리 실행 시간이 출력되게 해줘
3. 풀 고갈 상황을 의도적으로 만들 수 있는 엔드포인트 추가해줘
   (`GET /api/scenarios/pool-exhaustion` - 커넥션을 오래 점유)
4. Graceful shutdown 처리해줘 (커넥션 정리)
5. 에러 상황(타임아웃, 풀 고갈)에 대한 적절한 에러 응답 처리

## 기대 결과물

1. `docker-compose up` 한 번으로 전체 환경 실행
2. k6 스크립트로 다양한 부하 테스트 즉시 가능
3. 메트릭 엔드포인트로 실시간 풀 상태 관찰 가능
4. README만 따라하면 주니어도 풀 튜닝 개념을 체득할 수 있는 수준의 가이드